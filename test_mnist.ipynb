{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import labels2one_hot\n",
    "from generate_data import generate_data, generate_grid_data\n",
    "from modules import Dropout\n",
    "from modules import Linear, Sequential\n",
    "from modules.losses import LossMSE, LossCrossEntropy\n",
    "from optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot_labels(input, target, val=0):\n",
    "    tmp = input.new(target.size(0), target.max() + 1).fill_(-1)\n",
    "    tmp.scatter_(1, target.view(-1, 1), 1.0)\n",
    "    if val == 0:      \n",
    "        ret = (tmp+1)/2\n",
    "    if val == -1:\n",
    "        ret = tmp\n",
    "    return ret\n",
    "\n",
    "def load_data(one_hot_labels = False, normalize = False, flatten = True, data_dir = None, cifar = False, full = True, tiny = False, val = 0):\n",
    "\n",
    "    if data_dir is None:\n",
    "        \"\"\"\n",
    "        data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "        if data_dir is None:\n",
    "            data_dir = './data'\n",
    "        \"\"\"\n",
    "        data_dir = './data'\n",
    "        \n",
    "    if cifar is not None and cifar:\n",
    "        print('* Using CIFAR')\n",
    "        cifar_train_set = datasets.CIFAR10(data_dir + '/cifar10/', train = True, download = True)\n",
    "        cifar_test_set = datasets.CIFAR10(data_dir + '/cifar10/', train = False, download = True)\n",
    "\n",
    "        train_input = torch.from_numpy(cifar_train_set.train_data)\n",
    "        # Dirty hack to handle the change between torchvision 1.0.6 and 1.0.8\n",
    "        if train_input.size(3) == 3:\n",
    "            train_input = train_input.transpose(3, 1).transpose(2, 3).float()\n",
    "        else:\n",
    "            train_input = train_input.float()\n",
    "        train_target = torch.LongTensor(cifar_train_set.train_labels)\n",
    "\n",
    "        test_input = torch.from_numpy(cifar_test_set.test_data).float()\n",
    "        # Dirty hack to handle the change between torchvision 1.0.6 and 1.0.8\n",
    "        if test_input.size(3) == 3:\n",
    "            test_input = test_input.transpose(3, 1).transpose(2, 3).float()\n",
    "        else:\n",
    "            test_input = test_input.float()\n",
    "        test_target = torch.LongTensor(cifar_test_set.test_labels)\n",
    "\n",
    "    else:\n",
    "        print('* Using MNIST')\n",
    "        mnist_train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "        mnist_test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "\n",
    "        train_input = mnist_train_set.train_data.view(-1, 1, 28, 28).float()\n",
    "        train_target = mnist_train_set.train_labels\n",
    "        test_input = mnist_test_set.test_data.view(-1, 1, 28, 28).float()\n",
    "        test_target = mnist_test_set.test_labels\n",
    "\n",
    "    if flatten:\n",
    "        train_input = train_input.clone().view(train_input.size(0), -1)\n",
    "        test_input = test_input.clone().view(test_input.size(0), -1)\n",
    "\n",
    "    if full:\n",
    "        if tiny:\n",
    "            raise ValueError('Cannot have both --full and --tiny')\n",
    "    else:\n",
    "        if tiny:\n",
    "            print('** Reduce the data-set to the tiny setup')\n",
    "            train_input = train_input.narrow(0, 0, 500)\n",
    "            train_target = train_target.narrow(0, 0, 500)\n",
    "            test_input = test_input.narrow(0, 0, 100)\n",
    "            test_target = test_target.narrow(0, 0, 100)\n",
    "        else:\n",
    "            print('** Reduce the data-set (use --full for the full thing)')\n",
    "            train_input = train_input.narrow(0, 0, 1000)\n",
    "            train_target = train_target.narrow(0, 0, 1000)\n",
    "            test_input = test_input.narrow(0, 0, 1000)\n",
    "            test_target = test_target.narrow(0, 0, 1000)\n",
    "\n",
    "    print('** Use {:d} train and {:d} test samples'.format(train_input.size(0), test_input.size(0)))\n",
    "\n",
    "    if one_hot_labels:\n",
    "        train_target = convert_to_one_hot_labels(train_input, train_target, val=val)\n",
    "        test_target = convert_to_one_hot_labels(test_input, test_target, val=val)\n",
    "\n",
    "    if normalize:\n",
    "        mu, std = train_input.mean(), train_input.std()\n",
    "        train_input.sub_(mu).div_(std)\n",
    "        test_input.sub_(mu).div_(std)\n",
    "\n",
    "    return train_input, train_target, test_input, test_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Use 60000 train and 10000 test samples\n",
      "* Using MNIST\n",
      "** Use 60000 train and 10000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels = True, normalize = True, flatten = True, data_dir = None, cifar = False, full = True, tiny = False, val=0)\n",
    "train_input_mse, train_target_mse, test_input_mse, test_target_mse = load_data(one_hot_labels = True, normalize = True, flatten = True, data_dir = None, cifar = False, full = True, tiny = False, val=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        ...,\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1.,  1., -1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_net_1(x_all, y_all, num_of_neurons=(2, 25, 25, 25, 2), lr=0.1, momentum_coef=0.0, weight_decay=0.0, num_of_epochs=100):\n",
    "    ce = LossCrossEntropy()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Linear(out=num_of_neurons[1], input_size=num_of_neurons[0], activation='relu'))\n",
    "    model.add(Dropout(prob=0.2))\n",
    "    model.add(Linear(out=num_of_neurons[2], activation='relu'))\n",
    "    model.add(Dropout(prob=0.2))\n",
    "    model.add(Linear(out=num_of_neurons[3], activation='relu'))\n",
    "    model.add(Dropout(prob=0.2))\n",
    "    model.add(Linear(out=num_of_neurons[4], activation='softmax'))\n",
    "\n",
    "    model.loss = ce\n",
    "    sgd = SGD(lr, momentum_coef, weight_decay=0.0)\n",
    "\n",
    "    sgd.train(model, x_all, y_all, num_of_epochs, val_split=0.2, verbose=0)\n",
    "\n",
    "    return model\n",
    "\n",
    "def default_net_2(x_all, y_all, num_of_neurons=(2, 25, 25, 25, 2), lr=0.1, momentum_coef=0.0, weight_decay=0.0, num_of_epochs=100):\n",
    "    ce = LossCrossEntropy()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Linear(out=num_of_neurons[1], input_size=num_of_neurons[0], activation='relu'))\n",
    "    model.add(Linear(out=num_of_neurons[2], activation='relu'))\n",
    "    model.add(Linear(out=num_of_neurons[3], activation='relu'))\n",
    "    model.add(Linear(out=num_of_neurons[4], activation='softmax'))\n",
    "\n",
    "    model.loss = ce\n",
    "    sgd = SGD(lr, momentum_coef, weight_decay=0.2)\n",
    "\n",
    "    sgd.train(model, x_all, y_all, num_of_epochs, val_split=0.2, verbose=0)\n",
    "\n",
    "    return model\n",
    "\n",
    "def default_net_3(x_all, y_all, num_of_neurons=(2, 25, 25, 25, 2), lr=0.1, momentum_coef=0.0, num_of_epochs=100):\n",
    "    mse = LossMSE()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Linear(out=num_of_neurons[1], input_size=num_of_neurons[0], activation='relu'))\n",
    "    model.add(Dropout(prob=0.2))\n",
    "    model.add(Linear(out=num_of_neurons[2], activation='relu'))\n",
    "    model.add(Dropout(prob=0.2))\n",
    "    model.add(Linear(out=num_of_neurons[3], activation='relu'))\n",
    "    model.add(Dropout(prob=0.2))\n",
    "    model.add(Linear(out=num_of_neurons[4], activation='relu'))\n",
    "\n",
    "    model.loss = mse\n",
    "    sgd = SGD(lr, momentum_coef, weight_decay=0.2)\n",
    "\n",
    "    sgd.train(model, x_all, y_all, num_of_epochs, val_split=0.2, verbose=0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev: 100, current: 784\n",
      "Added Module Name: 0_Linear \n",
      "Added Module Name: 1_ReLU \n",
      "Added Module Name: 2_Dropout \n",
      "prev: 100, current: 100\n",
      "Added Module Name: 3_Linear \n",
      "Added Module Name: 4_ReLU \n",
      "Added Module Name: 5_Dropout \n",
      "prev: 100, current: 100\n",
      "Added Module Name: 6_Linear \n",
      "Added Module Name: 7_ReLU \n",
      "Added Module Name: 8_Dropout \n",
      "prev: 10, current: 100\n",
      "Added Module Name: 9_Linear \n",
      "Added Module Name: 10_Softmax \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]C:\\Users\\furkan\\Desktop\\EPFL\\ma\\ma2\\Deep Learning\\project\\project2\\dl-framework-master\\dl-framework-master\\modules\\losses.py:94: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  return loss_val[0]  # TODO: handle this accordingly with take_avg false\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [03:07<00:00,  1.88s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8321), tensor(0.5442), tensor([ 7,  2,  1,  ...,  4,  8,  6]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = default_net_1(train_input, train_target, num_of_neurons=(784, 100, 100, 100, 10), lr=0.1, momentum_coef=0.0, num_of_epochs=100)\n",
    "model1.evaluate(test_input, test_target, return_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev: 100, current: 784\n",
      "Added Module Name: 0_Linear \n",
      "Added Module Name: 1_ReLU \n",
      "prev: 100, current: 100\n",
      "Added Module Name: 2_Linear \n",
      "Added Module Name: 3_ReLU \n",
      "prev: 100, current: 100\n",
      "Added Module Name: 4_Linear \n",
      "Added Module Name: 5_ReLU \n",
      "prev: 10, current: 100\n",
      "Added Module Name: 6_Linear \n",
      "Added Module Name: 7_Softmax \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]C:\\Users\\furkan\\Desktop\\EPFL\\ma\\ma2\\Deep Learning\\project\\project2\\dl-framework-master\\dl-framework-master\\modules\\losses.py:94: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  return loss_val[0]  # TODO: handle this accordingly with take_avg false\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:47<00:00,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.9052), tensor(0.3296), tensor([ 7,  2,  1,  ...,  4,  5,  6]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = default_net_2(train_input, train_target, num_of_neurons=(784, 100, 100, 100, 10), lr=0.1, momentum_coef=0.0, num_of_epochs=100)\n",
    "model2.evaluate(test_input, test_target, return_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev: 100, current: 784\n",
      "Added Module Name: 0_Linear \n",
      "Added Module Name: 1_ReLU \n",
      "Added Module Name: 2_Dropout \n",
      "prev: 100, current: 100\n",
      "Added Module Name: 3_Linear \n",
      "Added Module Name: 4_ReLU \n",
      "Added Module Name: 5_Dropout \n",
      "prev: 100, current: 100\n",
      "Added Module Name: 6_Linear \n",
      "Added Module Name: 7_ReLU \n",
      "Added Module Name: 8_Dropout \n",
      "prev: 10, current: 100\n",
      "Added Module Name: 9_Linear \n",
      "Added Module Name: 10_ReLU \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [03:23<00:00,  2.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1.00000e-02 *\n",
       "        9.8200), tensor(10.), tensor([ 0,  0,  0,  ...,  0,  0,  0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = default_net_3(train_input_mse, train_target_mse, num_of_neurons=(784, 100, 100, 100, 10), lr=0.1, momentum_coef=0.0, num_of_epochs=100)\n",
    "model3.evaluate(test_input_mse, test_target_mse, return_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
