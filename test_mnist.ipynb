{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import labels2one_hot\n",
    "from generate_data import generate_data, generate_grid_data\n",
    "from modules import Dropout\n",
    "from modules import Linear, Sequential\n",
    "from modules.losses import LossCrossEntropy\n",
    "from optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot_labels(input, target):\n",
    "    tmp = input.new(target.size(0), target.max() + 1).fill_(-1)\n",
    "    tmp.scatter_(1, target.view(-1, 1), 1.0)\n",
    "    return tmp\n",
    "\n",
    "def load_data(one_hot_labels = False, normalize = False, flatten = True, data_dir = None, cifar = False, full = True, tiny = False):\n",
    "\n",
    "    if data_dir is None:\n",
    "        \"\"\"\n",
    "        data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "        if data_dir is None:\n",
    "            data_dir = './data'\n",
    "        \"\"\"\n",
    "        data_dir = './data'\n",
    "        \n",
    "    if cifar is not None and cifar:\n",
    "        print('* Using CIFAR')\n",
    "        cifar_train_set = datasets.CIFAR10(data_dir + '/cifar10/', train = True, download = True)\n",
    "        cifar_test_set = datasets.CIFAR10(data_dir + '/cifar10/', train = False, download = True)\n",
    "\n",
    "        train_input = torch.from_numpy(cifar_train_set.train_data)\n",
    "        # Dirty hack to handle the change between torchvision 1.0.6 and 1.0.8\n",
    "        if train_input.size(3) == 3:\n",
    "            train_input = train_input.transpose(3, 1).transpose(2, 3).float()\n",
    "        else:\n",
    "            train_input = train_input.float()\n",
    "        train_target = torch.LongTensor(cifar_train_set.train_labels)\n",
    "\n",
    "        test_input = torch.from_numpy(cifar_test_set.test_data).float()\n",
    "        # Dirty hack to handle the change between torchvision 1.0.6 and 1.0.8\n",
    "        if test_input.size(3) == 3:\n",
    "            test_input = test_input.transpose(3, 1).transpose(2, 3).float()\n",
    "        else:\n",
    "            test_input = test_input.float()\n",
    "        test_target = torch.LongTensor(cifar_test_set.test_labels)\n",
    "\n",
    "    else:\n",
    "        print('* Using MNIST')\n",
    "        mnist_train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "        mnist_test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "\n",
    "        train_input = mnist_train_set.train_data.view(-1, 1, 28, 28).float()\n",
    "        train_target = mnist_train_set.train_labels\n",
    "        test_input = mnist_test_set.test_data.view(-1, 1, 28, 28).float()\n",
    "        test_target = mnist_test_set.test_labels\n",
    "\n",
    "    if flatten:\n",
    "        train_input = train_input.clone().view(train_input.size(0), -1)\n",
    "        test_input = test_input.clone().view(test_input.size(0), -1)\n",
    "\n",
    "    if full:\n",
    "        if tiny:\n",
    "            raise ValueError('Cannot have both --full and --tiny')\n",
    "    else:\n",
    "        if tiny:\n",
    "            print('** Reduce the data-set to the tiny setup')\n",
    "            train_input = train_input.narrow(0, 0, 500)\n",
    "            train_target = train_target.narrow(0, 0, 500)\n",
    "            test_input = test_input.narrow(0, 0, 100)\n",
    "            test_target = test_target.narrow(0, 0, 100)\n",
    "        else:\n",
    "            print('** Reduce the data-set (use --full for the full thing)')\n",
    "            train_input = train_input.narrow(0, 0, 1000)\n",
    "            train_target = train_target.narrow(0, 0, 1000)\n",
    "            test_input = test_input.narrow(0, 0, 1000)\n",
    "            test_target = test_target.narrow(0, 0, 1000)\n",
    "\n",
    "    print('** Use {:d} train and {:d} test samples'.format(train_input.size(0), test_input.size(0)))\n",
    "\n",
    "    if one_hot_labels:\n",
    "        train_target = convert_to_one_hot_labels(train_input, train_target)\n",
    "        test_target = convert_to_one_hot_labels(test_input, test_target)\n",
    "\n",
    "    if normalize:\n",
    "        mu, std = train_input.mean(), train_input.std()\n",
    "        train_input.sub_(mu).div_(std)\n",
    "        test_input.sub_(mu).div_(std)\n",
    "\n",
    "    return train_input, train_target, test_input, test_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Use 60000 train and 10000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels = True, normalize = True, flatten = True, data_dir = None, cifar = False, full = True, tiny = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_net_1(x_all, y_all, num_of_neurons=(2, 25, 25, 25, 2), lr=0.1, momentum_coef=0.0, num_of_epochs=100):\n",
    "    ce = LossCrossEntropy()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Linear(out=num_of_neurons[1], input_size=num_of_neurons[0], activation='relu'))\n",
    "    model.add(Linear(out=num_of_neurons[2], activation='relu'))\n",
    "    model.add(Linear(out=num_of_neurons[2], activation='relu'))\n",
    "    model.add(Dropout(prob=0.2))\n",
    "    model.add(Linear(out=num_of_neurons[4], activation='softmax'))\n",
    "\n",
    "    model.loss = ce\n",
    "    sgd = SGD(lr, momentum_coef, weight_decay=0.2)\n",
    "\n",
    "    sgd.train(model, x_all, y_all, num_of_epochs, val_split=0.2)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev: 100, current: 784\n",
      "Added Module Name: 0_Linear \n",
      "Added Module Name: 1_ReLU \n",
      "prev: 100, current: 100\n",
      "Added Module Name: 2_Linear \n",
      "Added Module Name: 3_ReLU \n",
      "prev: 100, current: 100\n",
      "Added Module Name: 4_Linear \n",
      "Added Module Name: 5_ReLU \n",
      "Added Module Name: 6_Dropout \n",
      "prev: 10, current: 100\n",
      "Added Module Name: 7_Linear \n",
      "Added Module Name: 8_Softmax \n",
      "tensor([[ 0.0911,  0.0923,  0.1048,  ...,  0.0969,  0.0953,  0.1160],\n",
      "        [ 0.0848,  0.1034,  0.1107,  ...,  0.1066,  0.0936,  0.0984],\n",
      "        [ 0.0893,  0.0896,  0.1058,  ...,  0.1095,  0.1021,  0.1106],\n",
      "        ...,\n",
      "        [ 0.0820,  0.1000,  0.0938,  ...,  0.1140,  0.1043,  0.1017],\n",
      "        [ 0.0929,  0.0892,  0.1082,  ...,  0.1028,  0.0969,  0.1037],\n",
      "        [ 0.0962,  0.0856,  0.1081,  ...,  0.0991,  0.0986,  0.1059]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\furkan\\Desktop\\EPFL\\ma\\ma2\\Deep Learning\\project\\project2\\dl-framework-master\\dl-framework-master\\modules\\losses.py:95: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  return loss_val[0]  # TODO: handle this accordingly with take_avg false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0869,  0.1038,  0.1037,  ...,  0.1074,  0.1003,  0.0967],\n",
      "        [ 0.0919,  0.1022,  0.0987,  ...,  0.0965,  0.0938,  0.0949],\n",
      "        [ 0.0898,  0.1017,  0.1086,  ...,  0.1069,  0.0946,  0.1066],\n",
      "        ...,\n",
      "        [ 0.0796,  0.1015,  0.0987,  ...,  0.1189,  0.0962,  0.1029],\n",
      "        [ 0.0983,  0.0893,  0.0983,  ...,  0.0994,  0.0956,  0.1098],\n",
      "        [ 0.0932,  0.0992,  0.1094,  ...,  0.0988,  0.0904,  0.1017]])\n",
      "tensor([[ 0.0869,  0.1038,  0.1037,  ...,  0.1074,  0.1003,  0.0967],\n",
      "        [ 0.0919,  0.1022,  0.0987,  ...,  0.0965,  0.0938,  0.0949],\n",
      "        [ 0.0898,  0.1017,  0.1086,  ...,  0.1069,  0.0946,  0.1066],\n",
      "        ...,\n",
      "        [ 0.0796,  0.1015,  0.0987,  ...,  0.1189,  0.0962,  0.1029],\n",
      "        [ 0.0983,  0.0893,  0.0983,  ...,  0.0994,  0.0956,  0.1098],\n",
      "        [ 0.0932,  0.0992,  0.1094,  ...,  0.0988,  0.0904,  0.1017]])\n",
      "tensor([[ 0.0899,  0.0970,  0.1042,  ...,  0.1045,  0.1021,  0.1099],\n",
      "        [ 0.0926,  0.1022,  0.1051,  ...,  0.0967,  0.0883,  0.1092],\n",
      "        [ 0.0819,  0.0955,  0.1143,  ...,  0.1021,  0.0971,  0.1065],\n",
      "        ...,\n",
      "        [ 0.0910,  0.0914,  0.1037,  ...,  0.0998,  0.0983,  0.1096],\n",
      "        [ 0.0901,  0.1004,  0.1054,  ...,  0.1033,  0.0985,  0.1045],\n",
      "        [ 0.0881,  0.0917,  0.1022,  ...,  0.1120,  0.0995,  0.1013]])\n",
      "tensor([[ 0.0899,  0.0970,  0.1042,  ...,  0.1045,  0.1021,  0.1099],\n",
      "        [ 0.0926,  0.1022,  0.1051,  ...,  0.0967,  0.0883,  0.1092],\n",
      "        [ 0.0819,  0.0955,  0.1143,  ...,  0.1021,  0.0971,  0.1065],\n",
      "        ...,\n",
      "        [ 0.0910,  0.0914,  0.1037,  ...,  0.0998,  0.0983,  0.1096],\n",
      "        [ 0.0901,  0.1004,  0.1054,  ...,  0.1033,  0.0985,  0.1045],\n",
      "        [ 0.0881,  0.0917,  0.1022,  ...,  0.1120,  0.0995,  0.1013]])\n",
      "epoch: 0 ---> train_loss: -17.9139, train_acc: 0.08706250041723251 ----- val_loss: -17.9150, val_acc: 0.08666666597127914\n",
      "tensor([[ 0.0663,  0.0897,  0.1145,  ...,  0.0981,  0.0862,  0.1026],\n",
      "        [ 0.0665,  0.0925,  0.1289,  ...,  0.0883,  0.0957,  0.1080],\n",
      "        [ 0.0794,  0.0826,  0.1149,  ...,  0.0988,  0.0914,  0.1119],\n",
      "        ...,\n",
      "        [ 0.0607,  0.0830,  0.1205,  ...,  0.1114,  0.0983,  0.1133],\n",
      "        [ 0.0718,  0.0867,  0.1089,  ...,  0.0912,  0.0951,  0.0971],\n",
      "        [ 0.0573,  0.1110,  0.1516,  ...,  0.0890,  0.0962,  0.0799]])\n",
      "tensor([[ 0.0686,  0.0847,  0.1070,  ...,  0.0881,  0.0929,  0.1000],\n",
      "        [ 0.0674,  0.1045,  0.1240,  ...,  0.0820,  0.1003,  0.0906],\n",
      "        [ 0.0788,  0.0879,  0.1074,  ...,  0.0982,  0.0935,  0.1090],\n",
      "        ...,\n",
      "        [ 0.0664,  0.0891,  0.1227,  ...,  0.0783,  0.0724,  0.1117],\n",
      "        [ 0.0770,  0.0734,  0.1145,  ...,  0.0974,  0.0869,  0.1176],\n",
      "        [ 0.0713,  0.0812,  0.1332,  ...,  0.0789,  0.0906,  0.1069]])\n",
      "tensor([[ 0.0686,  0.0847,  0.1070,  ...,  0.0881,  0.0929,  0.1000],\n",
      "        [ 0.0674,  0.1045,  0.1240,  ...,  0.0820,  0.1003,  0.0906],\n",
      "        [ 0.0788,  0.0879,  0.1074,  ...,  0.0982,  0.0935,  0.1090],\n",
      "        ...,\n",
      "        [ 0.0664,  0.0891,  0.1227,  ...,  0.0783,  0.0724,  0.1117],\n",
      "        [ 0.0770,  0.0734,  0.1145,  ...,  0.0974,  0.0869,  0.1176],\n",
      "        [ 0.0713,  0.0812,  0.1332,  ...,  0.0789,  0.0906,  0.1069]])\n",
      "tensor([[ 0.0724,  0.0946,  0.1181,  ...,  0.1006,  0.0926,  0.1073],\n",
      "        [ 0.0657,  0.0839,  0.1278,  ...,  0.0857,  0.0840,  0.1026],\n",
      "        [ 0.0738,  0.0898,  0.1450,  ...,  0.0837,  0.0985,  0.1099],\n",
      "        ...,\n",
      "        [ 0.0641,  0.0839,  0.1235,  ...,  0.1033,  0.0782,  0.1134],\n",
      "        [ 0.0808,  0.0953,  0.1186,  ...,  0.0919,  0.1096,  0.0914],\n",
      "        [ 0.0804,  0.0922,  0.1155,  ...,  0.0909,  0.0941,  0.1066]])\n",
      "tensor([[ 0.0724,  0.0946,  0.1181,  ...,  0.1006,  0.0926,  0.1073],\n",
      "        [ 0.0657,  0.0839,  0.1278,  ...,  0.0857,  0.0840,  0.1026],\n",
      "        [ 0.0738,  0.0898,  0.1450,  ...,  0.0837,  0.0985,  0.1099],\n",
      "        ...,\n",
      "        [ 0.0641,  0.0839,  0.1235,  ...,  0.1033,  0.0782,  0.1134],\n",
      "        [ 0.0808,  0.0953,  0.1186,  ...,  0.0919,  0.1096,  0.0914],\n",
      "        [ 0.0804,  0.0922,  0.1155,  ...,  0.0909,  0.0941,  0.1066]])\n",
      "tensor([[ 3.0243e-04,  2.9814e-02,  6.6799e-02,  ...,  9.2948e-05,\n",
      "          1.6454e-03,  1.1649e-02],\n",
      "        [ 5.9224e-06,  8.3645e-04,  2.4893e-01,  ...,  4.0607e-05,\n",
      "          3.4032e-04,  2.4538e-03],\n",
      "        [ 8.7473e-04,  2.3197e-02,  4.3770e-01,  ...,  3.2203e-02,\n",
      "          8.9823e-03,  6.0213e-02],\n",
      "        ...,\n",
      "        [ 4.5591e-08,  1.6657e-04,  9.2666e-01,  ...,  6.1418e-06,\n",
      "          1.0175e-03,  6.9214e-04],\n",
      "        [ 3.2322e-04,  1.7130e-02,  1.0769e-02,  ...,  5.6515e-04,\n",
      "          8.6018e-02,  5.8217e-04],\n",
      "        [ 9.9339e-07,  1.4865e-03,  1.8533e-01,  ...,  1.1208e-06,\n",
      "          7.7796e-04,  4.6706e-04]])\n",
      "tensor([[ 3.5985e-05,  1.4387e-03,  9.9037e-02,  ...,  2.0490e-04,\n",
      "          1.1389e-02,  6.1747e-03],\n",
      "        [ 1.3983e-05,  1.1710e-03,  4.0052e-01,  ...,  2.4899e-04,\n",
      "          4.2722e-01,  7.0702e-03],\n",
      "        [ 3.9403e-03,  7.5271e-03,  5.7365e-01,  ...,  9.1798e-03,\n",
      "          2.1422e-02,  9.9676e-02],\n",
      "        ...,\n",
      "        [ 6.5166e-07,  1.0562e-03,  7.3927e-02,  ...,  1.4664e-04,\n",
      "          1.8692e-02,  1.6093e-04],\n",
      "        [ 2.5718e-05,  4.1908e-03,  2.4573e-01,  ...,  5.8778e-04,\n",
      "          3.7753e-04,  1.5445e-01],\n",
      "        [ 4.5147e-08,  7.5519e-04,  9.5791e-01,  ...,  1.1076e-04,\n",
      "          5.3562e-03,  1.8950e-02]])\n",
      "tensor([[ 3.5985e-05,  1.4387e-03,  9.9037e-02,  ...,  2.0490e-04,\n",
      "          1.1389e-02,  6.1747e-03],\n",
      "        [ 1.3983e-05,  1.1710e-03,  4.0052e-01,  ...,  2.4899e-04,\n",
      "          4.2722e-01,  7.0702e-03],\n",
      "        [ 3.9403e-03,  7.5271e-03,  5.7365e-01,  ...,  9.1798e-03,\n",
      "          2.1422e-02,  9.9676e-02],\n",
      "        ...,\n",
      "        [ 6.5166e-07,  1.0562e-03,  7.3927e-02,  ...,  1.4664e-04,\n",
      "          1.8692e-02,  1.6093e-04],\n",
      "        [ 2.5718e-05,  4.1908e-03,  2.4573e-01,  ...,  5.8778e-04,\n",
      "          3.7753e-04,  1.5445e-01],\n",
      "        [ 4.5147e-08,  7.5519e-04,  9.5791e-01,  ...,  1.1076e-04,\n",
      "          5.3562e-03,  1.8950e-02]])\n",
      "tensor([[ 2.5853e-04,  5.7751e-03,  4.1301e-01,  ...,  3.4765e-03,\n",
      "          6.7470e-02,  2.6395e-03],\n",
      "        [ 3.2108e-06,  2.2041e-03,  6.0244e-01,  ...,  9.2221e-05,\n",
      "          4.1096e-02,  3.1322e-02],\n",
      "        [ 1.5656e-05,  2.0435e-02,  3.2133e-01,  ...,  1.7363e-04,\n",
      "          1.5026e-03,  2.0784e-03],\n",
      "        ...,\n",
      "        [ 7.7767e-04,  2.5433e-03,  2.5645e-01,  ...,  3.1002e-04,\n",
      "          3.6857e-03,  1.0637e-01],\n",
      "        [ 8.1743e-04,  4.5705e-02,  1.7780e-01,  ...,  5.7934e-04,\n",
      "          1.7820e-01,  3.1912e-02],\n",
      "        [ 2.9379e-05,  2.7005e-03,  6.4079e-03,  ...,  4.2281e-05,\n",
      "          5.0696e-03,  6.9266e-04]])\n",
      "tensor([[ 2.5853e-04,  5.7751e-03,  4.1301e-01,  ...,  3.4765e-03,\n",
      "          6.7470e-02,  2.6395e-03],\n",
      "        [ 3.2108e-06,  2.2041e-03,  6.0244e-01,  ...,  9.2221e-05,\n",
      "          4.1096e-02,  3.1322e-02],\n",
      "        [ 1.5656e-05,  2.0435e-02,  3.2133e-01,  ...,  1.7363e-04,\n",
      "          1.5026e-03,  2.0784e-03],\n",
      "        ...,\n",
      "        [ 7.7767e-04,  2.5433e-03,  2.5645e-01,  ...,  3.1002e-04,\n",
      "          3.6857e-03,  1.0637e-01],\n",
      "        [ 8.1743e-04,  4.5705e-02,  1.7780e-01,  ...,  5.7934e-04,\n",
      "          1.7820e-01,  3.1912e-02],\n",
      "        [ 2.9379e-05,  2.7005e-03,  6.4079e-03,  ...,  4.2281e-05,\n",
      "          5.0696e-03,  6.9266e-04]])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000]])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000]])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000]])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        ...,\n",
      "        [ 1.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  1.0000]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cb322a6ba3b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_net_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_neurons\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum_coef\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_logging\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_grid_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_points_per_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-ac3963988a02>\u001b[0m in \u001b[0;36mdefault_net_1\u001b[1;34m(x_all, y_all, num_of_neurons, lr, momentum_coef, num_of_epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msgd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\ma\\ma2\\Deep Learning\\project\\project2\\dl-framework-master\\dl-framework-master\\optimizers\\sgd.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model, x_all, y_all, num_of_epochs, val_split, verbose)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mrange_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrange\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\ma\\ma2\\Deep Learning\\project\\project2\\dl-framework-master\\dl-framework-master\\optimizers\\sgd.py\u001b[0m in \u001b[0;36m_update_params\u001b[1;34m(self, model, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\ma\\ma2\\Deep Learning\\project\\project2\\dl-framework-master\\dl-framework-master\\modules\\sequential.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_input, y_input)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\EPFL\\ma\\ma2\\Deep Learning\\project\\project2\\dl-framework-master\\dl-framework-master\\modules\\losses.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, y_out, y_target)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \"\"\"\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# CHECK: given y_out must be a prob distribution e.g: softmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrel_tol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = default_net_1(train_input, train_target, num_of_neurons=(784, 100, 100, 100, 10), lr=0.1, momentum_coef=0.0, num_of_epochs=10)\n",
    "loss1 = model.loss.loss_logging\n",
    "\n",
    "x_test, y_test = generate_grid_data(minn=0, maxx=1, num_of_points_per_dim=51)\n",
    "\n",
    "model.evaluate(test_input, labels2one_hot(test_target, val=0), return_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
